{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bluehouseblah.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxC2FUg7nUNbJx12jcCCme",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dunnohow/Bert/blob/master/bluehouseblah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPvW1KQDCFtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "6d801f19-13fa-44ef-b66d-c383b3899713"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CWo8QmCCW9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d9369b7-8773-4ae3-a960-98afdc006d8a"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer # load language model & tokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXQFGst_KwSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f9a5028e-4cee-424b-e98a-38aee70c0ef5"
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRc5X1guCi_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtCDaWaMCndv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f6399d9-28d7-4357-c8ab-2b44f7fe32a8"
      },
      "source": [
        "# tokenizer test\n",
        "text = 'The BERT model was proposed in BERT'\n",
        "\n",
        "print(tokenizer(text))\n",
        "\n",
        "len(tokenizer(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 1996, 14324, 2944, 2001, 3818, 1999, 14324, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRAVVM3VCtwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ad5132a8-2d4b-4d50-da05-86aee85bb83d"
      },
      "source": [
        "# encode -> list type\n",
        "# encode 함수에 스페셜 토큰을 보고 싶지 않을 때에는 add_special_tokens = False 활용\n",
        "print(tokenizer.encode(text))\n",
        "print(tokenizer.encode(text, add_special_tokens = False)) # without special token"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1996, 14324, 2944, 2001, 3818, 1999, 14324, 102]\n",
            "[1996, 14324, 2944, 2001, 3818, 1999, 14324]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1wabwANCw12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "2636cbb4-8ca3-4598-bb70-46fbd55bc353"
      },
      "source": [
        "# decode\n",
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] the bert model was proposed in bert [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNCm1HJyDBi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = tokenizer.encode(text)\n",
        "input_ids_tensor = torch.tensor(input_ids, dtype = torch.long).unsqueeze(0).cuda()\n",
        "bert = BertModel.from_pretrained('bert-base-uncased').cuda()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Juw_I4jDFTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdb955fc-c7e1-4c76-951f-14a4bfbe851c"
      },
      "source": [
        "embeddings = bert(input_ids_tensor)\n",
        "embeddings[0]\n",
        "print(embeddings[0].shape) # |batch_size, # of tokens, bert dimension|"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 9, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMwQGySbDOaj",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "#**Load Data (청와대 청원 데이터)**\n",
        "\n",
        "<br>\n",
        "\n",
        "https://dacon.io/competitions/open/235597/overview/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1suMzANTDKgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be13a3f3-d843-410e-d794-2402a727df40"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sECt9SIoDivG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce6503dc-83f4-46e3-dddc-6c5e691eda67"
      },
      "source": [
        "path = \"drive/My Drive/NLP_practice/Blue-House/\"\n",
        "os.listdir(path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.csv', 'sample_submission.csv', 'test.csv', 'bluehouseblah.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ7O2sK1D7_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I3tJ4-uELoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7b0e8141-9330-43c5-bdb1-4ecbebfadbb0"
      },
      "source": [
        "train.iloc[:,[0,1]].describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40000.00000</td>\n",
              "      <td>40000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>19999.50000</td>\n",
              "      <td>1.001525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11547.14972</td>\n",
              "      <td>0.816449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9999.75000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>19999.50000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29999.25000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>39999.00000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             index      category\n",
              "count  40000.00000  40000.000000\n",
              "mean   19999.50000      1.001525\n",
              "std    11547.14972      0.816449\n",
              "min        0.00000      0.000000\n",
              "25%     9999.75000      0.000000\n",
              "50%    19999.50000      1.000000\n",
              "75%    29999.25000      2.000000\n",
              "max    39999.00000      2.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRxrqWMTpYF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a82aea4-c08d-4782-a85f-45a14408d36a"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>category</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  category                                               data\n",
              "0      0         2  신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지...\n",
              "1      1         0  학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등...\n",
              "2      2         1  빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올...\n",
              "3      3         1  티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠...\n",
              "4      4         1  무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLtVvTnHzHce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9c59bcb9-3417-4577-951c-d93a8999c864"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>소년법 폐지해주세요. 법 아래에서 보호받아야 할 아이들이\\n법으로 인해 보호받지 못...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>국공립 유치원 증설에 관하여. 국공립 유치원 부지 학보와건립및 증설에\\n*지역 어린...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>나경원파면. 나경원의원의  동계올림픽 위원을 파면해 주세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>국민위원에가 삼성편만들어요. 삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>방과후,유치원,어린이집 영어교육을 유지시켜주세요. 저는 아이 셋 키우는 평범한 주부...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                               data\n",
              "0      0  소년법 폐지해주세요. 법 아래에서 보호받아야 할 아이들이\\n법으로 인해 보호받지 못...\n",
              "1      1  국공립 유치원 증설에 관하여. 국공립 유치원 부지 학보와건립및 증설에\\n*지역 어린...\n",
              "2      2                   나경원파면. 나경원의원의  동계올림픽 위원을 파면해 주세요\n",
              "3      3  국민위원에가 삼성편만들어요. 삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 ...\n",
              "4      4  방과후,유치원,어린이집 영어교육을 유지시켜주세요. 저는 아이 셋 키우는 평범한 주부..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Ip8B3QGzOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-multilingual-cased').cuda()\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpKwJbvRFNc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "84c034e4-c23f-4c3f-9874-846e0d549e38"
      },
      "source": [
        "# 데이터 문장 길이가 다르기 때문에 [PAD] token을 활용해야함, 또한 최대 길이도 정해야함\n",
        "print(train['data'][0])\n",
        "print(tokenizer.encode(train['data'][0]))\n",
        "print(len(tokenizer.encode(train['data'][0])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지 마시고\\n보편적으로 모든국민이 수긍할  수 있는 복지정책 펴 주시길 바랍니다.\\n저도 신혼부부이지만 당첨되는 사람 로또되는 이런주택정책 반대합니다.\\n국민세금을 일부 사람들에게 퍼주기식이 되면 안되죠..\\n그 세금으로 우리아이 안전하게 맡길 수 있는 보육시설을 전국에 설치해 주세요..\\n대기업들은 솔선수범해서 모든 사업장에 의무설치 할 수 있도록 하시구요..\\n집 보다 애 맡길데가 없어 경력단절 되는게 더 괴롭습니다.!\\n집은 개인의 능력을 키워 사는게 맞습니다.\\n그 능력을 키울수 있도록 육아 전담에 힘을 기울이는게 맞습니다.\\n우리아이 부모가 키우는거 맞지만 이제는 국가가\\n책임지는 시대로 가는게 맞다고 봅니다.\\n그렇잖아도 부동산 가격 자꾸 올라가는게 정부정책이 잘못 되었다고 봅니다.\\n부동산은 그냥 내버려 두세요!  좀!\\n건들수록 역효과네요..\n",
            "[101, 9487, 119439, 14646, 14646, 19855, 11102, 9689, 119342, 16605, 119254, 106154, 9356, 83811, 14040, 31928, 9044, 26737, 16323, 24982, 48549, 119, 119, 8909, 36553, 24982, 40032, 11467, 47807, 11513, 28195, 9670, 119254, 119396, 12508, 9246, 14040, 11664, 165, 182, 30005, 50450, 17022, 25701, 20479, 36553, 10739, 9460, 118665, 14843, 9460, 13767, 9357, 12508, 16605, 119254, 9923, 9689, 14040, 118666, 9318, 118853, 48345, 119, 165, 182, 48387, 12092, 9487, 119439, 14646, 14646, 44359, 19105, 9067, 119260, 24683, 9405, 61250, 9202, 118839, 24683, 80956, 16323, 119342, 16605, 119254, 9321, 14423, 33188, 48345, 119, 165, 182, 20479, 36553, 24982, 40032, 10622, 47807, 9405, 61250, 61688, 9913, 16323, 12310, 21155, 10739, 9098, 14867, 9521, 118800, 119217, 119, 119, 165, 182, 78136, 9435, 40032, 11467, 9604, 31065, 10739, 9521, 16617, 17594, 9257, 118666, 9460, 13767, 9356, 83811, 14040, 31928, 10622, 9665, 20479, 10530, 102221, 14523, 9689, 24982, 48549, 119, 119, 165, 182, 14423, 12310, 26784, 22879, 9451, 18471, 15891, 108056, 70146, 25701, 9405, 26784, 85903, 9637, 32537, 31928, 18622, 9955, 9460, 107931, 9952, 14040, 17196, 48549, 119, 119, 165, 182, 38696, 106154, 9532, 9257, 118666, 28911, 11287, 9555, 12965, 8885, 28143, 24989, 58931, 54780, 14153, 9074, 8905, 118884, 119081, 48345, 119, 106, 165, 182, 38696, 10892, 8857, 48418, 9046, 33975, 9838, 69592, 9405, 11018, 14153, 9256, 119081, 48345, 119, 165, 182, 78136, 9046, 33975, 9838, 78123, 15891, 107931, 9626, 16985, 9665, 105462, 10530, 10028, 10622, 8932, 78123, 31728, 14153, 9256, 119081, 48345, 119, 165, 182, 27355, 31065, 10739, 9365, 39420, 11287, 9838, 27355, 11018, 41521, 9256, 28578, 9638, 87164, 93222, 11287, 165, 182, 119254, 36240, 32815, 102080, 11261, 8843, 11018, 14153, 9256, 85634, 100, 119, 165, 100, 9365, 18778, 21386, 8843, 45465, 9651, 118694, 9583, 17342, 68828, 14153, 9670, 14646, 16605, 119254, 10739, 9654, 118940, 17737, 11664, 100, 119, 165, 182, 14646, 18778, 21386, 10892, 8924, 118729, 8996, 41605, 26737, 9102, 24982, 48549, 106, 9682, 106, 165, 182, 71439, 27023, 15891, 31398, 9566, 119449, 11882, 77884, 48549, 119, 119, 102]\n",
            "326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UScQQeSEyPnW",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "#**Train set pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcxZpFOfrb4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3233777e-09b1-4860-cfa9-51faa66e9c81"
      },
      "source": [
        "# 청원 문장 추출\n",
        "sentences = train['data']\n",
        "sentences[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지...\n",
              "1    학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등...\n",
              "2    빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올...\n",
              "3    티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠...\n",
              "4    무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타...\n",
              "5    일간베스트 사이트 폐쇠를 청원합니다. 국익에 전혀 도움이 되지  않고 국민에게 해를...\n",
              "6    '초중고학교 페미니즘교육의무화'중복동의인원 무효처리해 주세요!!. 국민들의 요구를 ...\n",
              "7    수시 발표도 다 7일 미뤄주세요.. 수능 전 발표를 피하기 위해 수능 후 발표나는 ...\n",
              "8    여성부 폐지 청원합니다.. 여성이 인구 절반인데 여성 관련 정책은 보건복지부 기획재...\n",
              "9    왜 제 수백만원짜리 녹취록을 증거로 인정해 주지 않습니까?. 한 사람을 잘 못 만난...\n",
              "Name: data, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0RsoLj5rq5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3248612c-e3dd-4f87-e175-8ee3915ade2c"
      },
      "source": [
        "# 스페셜 토큰 추가\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지 마시고\\\\n보편적으로 모든국민이 수긍할  수 있는 복지정책 펴 주시길 바랍니다.\\\\n저도 신혼부부이지만 당첨되는 사람 로또되는 이런주택정책 반대합니다.\\\\n국민세금을 일부 사람들에게 퍼주기식이 되면 안되죠..\\\\n그 세금으로 우리아이 안전하게 맡길 수 있는 보육시설을 전국에 설치해 주세요..\\\\n대기업들은 솔선수범해서 모든 사업장에 의무설치 할 수 있도록 하시구요..\\\\n집 보다 애 맡길데가 없어 경력단절 되는게 더 괴롭습니다.!\\\\n집은 개인의 능력을 키워 사는게 맞습니다.\\\\n그 능력을 키울수 있도록 육아 전담에 힘을 기울이는게 맞습니다.\\\\n우리아이 부모가 키우는거 맞지만 이제는 국가가\\\\n책임지는 시대로 가는게 맞다고 봅니다.\\\\n그렇잖아도 부동산 가격 자꾸 올라가는게 정부정책이 잘못 되었다고 봅니다.\\\\n부동산은 그냥 내버려 두세요!  좀!\\\\n건들수록 역효과네요.. [SEP]',\n",
              " \"[CLS] 학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등 글짓기를 하다 생각했습니다 우리 울산엔 '울산중학교'는 두개입니다 하나는 남중,하나는 여중인데 어째서 우리학교만 '여자'를 붙여야하는가 하고요 남자가 우위였던 때 지어졌던 학교라 그런진 모르겠지만 울산중학교(남중)에도 '남자'를 붙여 울산남자중학교가 되게 해주세요\\\\n평소에 학교이름을 줄여 부를때에도 우리학교는 울여중,남중은 그냥 울중 이라 부릅니다 몇년동안 그리 불러온, 너무나 익숙해진 이 현실을 이젠 바꿀때가 되지않았나 싶네요,,지금은 조선시대가 아니니까요\\\\n국내에 이런 학교는 널렸습니다 울산뿐만이 아니라 국내 다른 중/고등학교에 있는 똑같은 문제들을 해결해주셨으면 합니다... [SEP]\",\n",
              " '[CLS] 빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올림픽에서 김보름, 박지우 선수와 관련해서 큰 논란거리가 되고 있는데요. 선수 개개인의 문제를 떠나서 이번일에 대해 대한빙상연맹의 불합리한 행정에 불신을 갖고있는 사람들이 많습니다. 이제 동계올림픽도 폐막일이 다가오고, 6월이 되면 러시아에서 4년마다 열리는 월드컵 축구대회가 열리는데요.  월드컵이 시작도 하기전부터 감독선임, 선수선발에 대해 우려의 목소리를 내는 사람들이 정말 많습니다.\\\\n아시아 최종예선 내내 기대이하의 경기력으로 실망스러운 모습을 보인건 둘째 치더라도 슈틸리케 감독을 경질하고, 2016 리우 올림픽 감독을 맡았던 신태용 감독을 A대표팀 감독에 앉히는 모습이 마치 2014 브라질 월드컵때 2012 런던 올림픽 감독이었던 홍명보 감독을 앉히는 모습과 모양새가 너무도 흡사하구요. 최근 평가전에서 김영권, 장현수등등 일부 경기력에 논란이 많은 선수들을 계속해서 기용하는 모습까지 4년전 실패와 아픔(선수단 귀국후 공항에서 엿세례)을 그대로 되풀이 하려는건가? 싶을 정도로 4년전과 모습이 너무나도 흡사합니다.\\\\n빙상연맹과 관련해서는 최근 많은 논란이 되고있고, 다른분들께서 많이 이야기해 주셨으니 더 이상 언급하지는 않겠습니다. 제가 하고 싶은 이야기는 이번일을 계기로 대한빙상연맹, 대한축구협회를 비롯한 각종 체육협회의 잘못된 비리, 부조리들을 철저하게 밝혀서 모든 스포츠에 있어서 감독선임부터 선수선발까지 모든 과정들이 인맥,파벌에 의하지 않고 공정하고 투명하게 이뤄질 수 있도록 힘써 주셨으면 합니다. [SEP]',\n",
              " '[CLS] 티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠시 딴일이 생겨 동생들에게 리모컨을 주고  알이서 방송을 보라고 했습니다.그런데 유독 다른 만화에 비해 폭력성이 강한 것 같아 연령등급을 확인해 보니 12세 관람가라고 되어 있었습니다.하지만 성인물이 아니어서 특별히 방송전 연령을 고지하는 것 외에는 하지않는걸 보고놀랐습니다.티비12세관람가도 연령인증 안하면 안되는 줄 알았는데 알고보니 12세,15세 관람가의 경우 연령고지만 하였기때문입니다.따라서 성인물도 주민번호와 전화번호를 확인하고 볼수있는 것처럼 청소년인지 아닌지에 대한 여부를 살펴볼 필요가 있습니다.성인물만이 어린이(13세미만)에게 해로운 것이 아닙니다.청소년 관람가도 어린이에게 해로운 부분이 있기에 연령등급을 주는 것입니다.반드시 관람등급이 지켜질수 있도록 12세,15세 관람가 등급 연령확인 의무화를 해주세요. [SEP]',\n",
              " '[CLS] 무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타이와 반바지등 시원한 복장을 정부부처와 공공기관, 공기업과 대기업이 앞장서서 했으면 합니다.\\\\n여성들은 짧은 초미니스커트와 팬티가 보일듯 짧은 치마만 입어도 무더운 여름철 시원한것 이 당연한 것입니다. 슬리퍼  차림으로 직장에 다녀도 누가 뭐라 하는이도 없고 말입니다. 하지만 남자가 반바지를 입으면 고정관념을 갖고 편견섞인 시선으로 부정적으로 바로보는 경우가 많은 것입니다.  흔한예로 \"직장에 놀러왔냐?\"는등 편견섞인 시선과 말을 듣게 되는 경우가 허다합니다.\\\\n그냥 시원하게 반바지 입고 다니면 되지하고 말하진 말기 바랍니다. 물론 그렇게 시선 무시하고 입을수도 있지만 지금 말하는건(?) 그게 아닌거 아시지요?\\\\n즉 고정관념을 떨치고 편견섞인 시선으로 바라보는 문화를 지양하자는 것입니다. 그건 한두명의 힘으로 되는것이 아니라, 우리모두의 관심과 동참이 필요한 것입니다.\\\\n중국고대의서(소녀경 & 방중술)에 보더라도 여자는 \"물\"에 비유하고, 남자는 \\'불\\'에 비유할 정도로 남성들이 더위에 더 취약하고 많이 더위를 탈수 있는것 입니다.  그런데 현실에서는 그렇지 못하고 숨이 턱턱만히는 여름철에도 햇볕을 흡수해서 더 더운 검은색정장에다 넥타이로 목까지 졸라대는 것을 매너라고 여기며 은연중에 반강제로 입게 합니다.\\\\n이런 문화를 실용적으로 바꾸어 더운날씨엔 더운날씨에 맞게 시원한 자율복장을 할수 있게끔 하고, 그중에서도 추위를 많이 타는 사람은 긴팔을 입으면 되겠죠?\\\\n여러분의 동참으로 올여름에는 남성들도 시원한 여름을 날수 있었음 하는 바람이 간절합니다. [SEP]',\n",
              " '[CLS] 일간베스트 사이트 폐쇠를 청원합니다. 국익에 전혀 도움이 되지  않고 국민에게 해를 끼칩니다 [SEP]',\n",
              " \"[CLS] '초중고학교 페미니즘교육의무화'중복동의인원 무효처리해 주세요!!. 국민들의 요구를 묵살해도 되나요? 명백한 증거가 있고 부정한 방법을 동원해 목표달성인원을 충족한 해당 청원에 대하여 청와대는 왜 아무런 조치를 취하지 않나요?? 중복 동의된 인원은 무효처리 후 인원 수를 다시 계상해야 정상적이지 않나요?? 청와대가 언제부터 부정한 청원에 대하여 방관하고 용인하였나요??\\\\n잘못된 부분은 시정하고 바로잡아야 하지 않나요??? 일국의 청와대씩이나 돼 갖고...\\\\n21만여 표 중에서 중복처리된 부분은 무효처리한 후 다시 숫자를 집계하여 주세요...\\\\n하물며 정부답변 청원이쟎아요...청와대가 이래서야 되겠습니까??\\\\n인터넷은 전 세계인이 들락날락하는 공간이에요..\\\\n어휴, 창피해!! [SEP]\",\n",
              " '[CLS] 수시 발표도 다 7일 미뤄주세요.. 수능 전 발표를 피하기 위해 수능 후 발표나는 전형으로만 다 준비해놨는데 수능이 7일 미뤄지니 당장 이번주 금요일, 미뤄진 수능 전날 수시 종합 발표가 난다니 당황스럽습니다. 수능 연기에 대해서는 불만이 없지만, 지금 삼육대, 경기대 등 다수 학교가 원래 일정대로 최저 없는 전형에서 발표를 강행한다고 공지를 내놓았는데 이건 옳지 않다고 생각합니다. 수능 전에 수시 발표가 난다는 것이 얼마나 마음에 동요가 되는지, 수능 성적에 얼마나 큰 영향을 끼칭 것을 감수하고 전형을 선택하는 것인지 알아주시길 바랍니다. 차질 없도록 논술, 면접, 발표를 똑같이 7일 미루도록 지시해주십시오. [SEP]',\n",
              " '[CLS] 여성부 폐지 청원합니다.. 여성이 인구 절반인데 여성 관련 정책은 보건복지부 기획재정부 교육부 교육 노동부 등 이런데 부처에서 양성평등 성 평등 여성에 관한 복지 확대를 하면 되는 건데 굳이 여성부라고 따로 만들 의미가 있을까요?\\\\n여성부 있는 지금 오히려 국민들 사이에 성 평등에 갈라져 있는 실태입니다 ...\\\\n일을 제대로 안되고 있다는 소리이죠 .. 국민들은 힘들게 번 돈입니다 국민들 위해서 한 번 더 생각을 조금 해주셨습니다 좋겠습니다 .. 정말 나라다운 나라 실행해주세요 .. [SEP]',\n",
              " '[CLS] 왜 제 수백만원짜리 녹취록을 증거로 인정해 주지 않습니까?. 한 사람을 잘 못 만난 죄로 실직을 당하고 평생을 꽃뱀, 성매매범으로 살아가게 되었습니다.\\\\n저는 2017년 약 3개월간 주민등록증을 변조하여 신상을 위조한 피의자를 만나는 동안 갖은 협박과 폭행을 당했고, 만남을 거부하자 직장으로 전화를 걸어 실직 당하게 만들고 몇 명인지 가늠조차 할 수 없는 수많은 동호인들에게 꽃뱀, 성매매범으로 허위사실과 cctv동영상을 유포하였습니다.\\\\n저는 절대 꽃뱀도 성매매범도 폭행범도 아니기에 5차례의 형사고소를 하여, 현재 검찰조사중인 2건과 항고중인 2건이 있습니다.\\\\n첫 번째 고소건의 여러 범죄 중 한 건만 모욕죄로 기소 됨으로 인해 제가 죽을 때까지 따라다니며 괴롭히겠다고 상습범죄자 피의자는 현재까지 저를 위협할 목적으로 따라다니거나 제가 소속되어 있는 클럽 밴드마다 꽃뱀 운운하는 댓글을 게시하고 있습니다. 또한 여러 정치계 인사(17년 모시장과 친구, 18년 모시장후보의 선거본부장, 현재는 더불어 민주당 부위원장)의 친분을 과시하고 돈을 뿌리며 구장마다 돌아다니면서 허위사실 유포 및 동호인들과 증인을 매수(친구처럼 지낸 동호인이 거짓 참고인 진술 등)하여 범죄를 방조하게 만들었습니다.\\\\n저는 생각만 해도 치가 떨리는 지난 악몽과 피의자의 목소리를 수차례 쉼 없이 눈물을 흘리며 듣고 또 들으며, 피의자의 범죄를 인정받기 위해 수백만원을 들여 녹취록을 증거로 제출했으나 증거로 인정받지 못했습니다.\\\\n저는 꽃뱀, 성매매범, 폭행범이 아닙니다.\\\\n제발 제가 제출한 녹취록을 비롯한 모든 자료를 증거로 인정해 주시기 바랍니다.\\\\n상습범죄자가 더는 사회질서를 어지럽히지 못하도록 구속하여 최고의 형벌로 다스려 주시기  바랍니다. [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md2WcVoSuG5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "dcede05f-3f01-4c42-f49c-a3f37a32cd37"
      },
      "source": [
        "# 문장 단위\"\\\\n\" 제거\n",
        "sentences = [sentence.replace('\\\\n', '.') for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지 마시고.보편적으로 모든국민이 수긍할  수 있는 복지정책 펴 주시길 바랍니다..저도 신혼부부이지만 당첨되는 사람 로또되는 이런주택정책 반대합니다..국민세금을 일부 사람들에게 퍼주기식이 되면 안되죠...그 세금으로 우리아이 안전하게 맡길 수 있는 보육시설을 전국에 설치해 주세요...대기업들은 솔선수범해서 모든 사업장에 의무설치 할 수 있도록 하시구요...집 보다 애 맡길데가 없어 경력단절 되는게 더 괴롭습니다.!.집은 개인의 능력을 키워 사는게 맞습니다..그 능력을 키울수 있도록 육아 전담에 힘을 기울이는게 맞습니다..우리아이 부모가 키우는거 맞지만 이제는 국가가.책임지는 시대로 가는게 맞다고 봅니다..그렇잖아도 부동산 가격 자꾸 올라가는게 정부정책이 잘못 되었다고 봅니다..부동산은 그냥 내버려 두세요!  좀!.건들수록 역효과네요.. [SEP]',\n",
              " \"[CLS] 학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등 글짓기를 하다 생각했습니다 우리 울산엔 '울산중학교'는 두개입니다 하나는 남중,하나는 여중인데 어째서 우리학교만 '여자'를 붙여야하는가 하고요 남자가 우위였던 때 지어졌던 학교라 그런진 모르겠지만 울산중학교(남중)에도 '남자'를 붙여 울산남자중학교가 되게 해주세요.평소에 학교이름을 줄여 부를때에도 우리학교는 울여중,남중은 그냥 울중 이라 부릅니다 몇년동안 그리 불러온, 너무나 익숙해진 이 현실을 이젠 바꿀때가 되지않았나 싶네요,,지금은 조선시대가 아니니까요.국내에 이런 학교는 널렸습니다 울산뿐만이 아니라 국내 다른 중/고등학교에 있는 똑같은 문제들을 해결해주셨으면 합니다... [SEP]\",\n",
              " '[CLS] 빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올림픽에서 김보름, 박지우 선수와 관련해서 큰 논란거리가 되고 있는데요. 선수 개개인의 문제를 떠나서 이번일에 대해 대한빙상연맹의 불합리한 행정에 불신을 갖고있는 사람들이 많습니다. 이제 동계올림픽도 폐막일이 다가오고, 6월이 되면 러시아에서 4년마다 열리는 월드컵 축구대회가 열리는데요.  월드컵이 시작도 하기전부터 감독선임, 선수선발에 대해 우려의 목소리를 내는 사람들이 정말 많습니다..아시아 최종예선 내내 기대이하의 경기력으로 실망스러운 모습을 보인건 둘째 치더라도 슈틸리케 감독을 경질하고, 2016 리우 올림픽 감독을 맡았던 신태용 감독을 A대표팀 감독에 앉히는 모습이 마치 2014 브라질 월드컵때 2012 런던 올림픽 감독이었던 홍명보 감독을 앉히는 모습과 모양새가 너무도 흡사하구요. 최근 평가전에서 김영권, 장현수등등 일부 경기력에 논란이 많은 선수들을 계속해서 기용하는 모습까지 4년전 실패와 아픔(선수단 귀국후 공항에서 엿세례)을 그대로 되풀이 하려는건가? 싶을 정도로 4년전과 모습이 너무나도 흡사합니다..빙상연맹과 관련해서는 최근 많은 논란이 되고있고, 다른분들께서 많이 이야기해 주셨으니 더 이상 언급하지는 않겠습니다. 제가 하고 싶은 이야기는 이번일을 계기로 대한빙상연맹, 대한축구협회를 비롯한 각종 체육협회의 잘못된 비리, 부조리들을 철저하게 밝혀서 모든 스포츠에 있어서 감독선임부터 선수선발까지 모든 과정들이 인맥,파벌에 의하지 않고 공정하고 투명하게 이뤄질 수 있도록 힘써 주셨으면 합니다. [SEP]',\n",
              " '[CLS] 티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠시 딴일이 생겨 동생들에게 리모컨을 주고  알이서 방송을 보라고 했습니다.그런데 유독 다른 만화에 비해 폭력성이 강한 것 같아 연령등급을 확인해 보니 12세 관람가라고 되어 있었습니다.하지만 성인물이 아니어서 특별히 방송전 연령을 고지하는 것 외에는 하지않는걸 보고놀랐습니다.티비12세관람가도 연령인증 안하면 안되는 줄 알았는데 알고보니 12세,15세 관람가의 경우 연령고지만 하였기때문입니다.따라서 성인물도 주민번호와 전화번호를 확인하고 볼수있는 것처럼 청소년인지 아닌지에 대한 여부를 살펴볼 필요가 있습니다.성인물만이 어린이(13세미만)에게 해로운 것이 아닙니다.청소년 관람가도 어린이에게 해로운 부분이 있기에 연령등급을 주는 것입니다.반드시 관람등급이 지켜질수 있도록 12세,15세 관람가 등급 연령확인 의무화를 해주세요. [SEP]',\n",
              " '[CLS] 무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타이와 반바지등 시원한 복장을 정부부처와 공공기관, 공기업과 대기업이 앞장서서 했으면 합니다..여성들은 짧은 초미니스커트와 팬티가 보일듯 짧은 치마만 입어도 무더운 여름철 시원한것 이 당연한 것입니다. 슬리퍼  차림으로 직장에 다녀도 누가 뭐라 하는이도 없고 말입니다. 하지만 남자가 반바지를 입으면 고정관념을 갖고 편견섞인 시선으로 부정적으로 바로보는 경우가 많은 것입니다.  흔한예로 \"직장에 놀러왔냐?\"는등 편견섞인 시선과 말을 듣게 되는 경우가 허다합니다..그냥 시원하게 반바지 입고 다니면 되지하고 말하진 말기 바랍니다. 물론 그렇게 시선 무시하고 입을수도 있지만 지금 말하는건(?) 그게 아닌거 아시지요?.즉 고정관념을 떨치고 편견섞인 시선으로 바라보는 문화를 지양하자는 것입니다. 그건 한두명의 힘으로 되는것이 아니라, 우리모두의 관심과 동참이 필요한 것입니다..중국고대의서(소녀경 & 방중술)에 보더라도 여자는 \"물\"에 비유하고, 남자는 \\'불\\'에 비유할 정도로 남성들이 더위에 더 취약하고 많이 더위를 탈수 있는것 입니다.  그런데 현실에서는 그렇지 못하고 숨이 턱턱만히는 여름철에도 햇볕을 흡수해서 더 더운 검은색정장에다 넥타이로 목까지 졸라대는 것을 매너라고 여기며 은연중에 반강제로 입게 합니다..이런 문화를 실용적으로 바꾸어 더운날씨엔 더운날씨에 맞게 시원한 자율복장을 할수 있게끔 하고, 그중에서도 추위를 많이 타는 사람은 긴팔을 입으면 되겠죠?.여러분의 동참으로 올여름에는 남성들도 시원한 여름을 날수 있었음 하는 바람이 간절합니다. [SEP]',\n",
              " '[CLS] 일간베스트 사이트 폐쇠를 청원합니다. 국익에 전혀 도움이 되지  않고 국민에게 해를 끼칩니다 [SEP]',\n",
              " \"[CLS] '초중고학교 페미니즘교육의무화'중복동의인원 무효처리해 주세요!!. 국민들의 요구를 묵살해도 되나요? 명백한 증거가 있고 부정한 방법을 동원해 목표달성인원을 충족한 해당 청원에 대하여 청와대는 왜 아무런 조치를 취하지 않나요?? 중복 동의된 인원은 무효처리 후 인원 수를 다시 계상해야 정상적이지 않나요?? 청와대가 언제부터 부정한 청원에 대하여 방관하고 용인하였나요??.잘못된 부분은 시정하고 바로잡아야 하지 않나요??? 일국의 청와대씩이나 돼 갖고....21만여 표 중에서 중복처리된 부분은 무효처리한 후 다시 숫자를 집계하여 주세요....하물며 정부답변 청원이쟎아요...청와대가 이래서야 되겠습니까??.인터넷은 전 세계인이 들락날락하는 공간이에요...어휴, 창피해!! [SEP]\",\n",
              " '[CLS] 수시 발표도 다 7일 미뤄주세요.. 수능 전 발표를 피하기 위해 수능 후 발표나는 전형으로만 다 준비해놨는데 수능이 7일 미뤄지니 당장 이번주 금요일, 미뤄진 수능 전날 수시 종합 발표가 난다니 당황스럽습니다. 수능 연기에 대해서는 불만이 없지만, 지금 삼육대, 경기대 등 다수 학교가 원래 일정대로 최저 없는 전형에서 발표를 강행한다고 공지를 내놓았는데 이건 옳지 않다고 생각합니다. 수능 전에 수시 발표가 난다는 것이 얼마나 마음에 동요가 되는지, 수능 성적에 얼마나 큰 영향을 끼칭 것을 감수하고 전형을 선택하는 것인지 알아주시길 바랍니다. 차질 없도록 논술, 면접, 발표를 똑같이 7일 미루도록 지시해주십시오. [SEP]',\n",
              " '[CLS] 여성부 폐지 청원합니다.. 여성이 인구 절반인데 여성 관련 정책은 보건복지부 기획재정부 교육부 교육 노동부 등 이런데 부처에서 양성평등 성 평등 여성에 관한 복지 확대를 하면 되는 건데 굳이 여성부라고 따로 만들 의미가 있을까요?.여성부 있는 지금 오히려 국민들 사이에 성 평등에 갈라져 있는 실태입니다 ....일을 제대로 안되고 있다는 소리이죠 .. 국민들은 힘들게 번 돈입니다 국민들 위해서 한 번 더 생각을 조금 해주셨습니다 좋겠습니다 .. 정말 나라다운 나라 실행해주세요 .. [SEP]',\n",
              " '[CLS] 왜 제 수백만원짜리 녹취록을 증거로 인정해 주지 않습니까?. 한 사람을 잘 못 만난 죄로 실직을 당하고 평생을 꽃뱀, 성매매범으로 살아가게 되었습니다..저는 2017년 약 3개월간 주민등록증을 변조하여 신상을 위조한 피의자를 만나는 동안 갖은 협박과 폭행을 당했고, 만남을 거부하자 직장으로 전화를 걸어 실직 당하게 만들고 몇 명인지 가늠조차 할 수 없는 수많은 동호인들에게 꽃뱀, 성매매범으로 허위사실과 cctv동영상을 유포하였습니다..저는 절대 꽃뱀도 성매매범도 폭행범도 아니기에 5차례의 형사고소를 하여, 현재 검찰조사중인 2건과 항고중인 2건이 있습니다..첫 번째 고소건의 여러 범죄 중 한 건만 모욕죄로 기소 됨으로 인해 제가 죽을 때까지 따라다니며 괴롭히겠다고 상습범죄자 피의자는 현재까지 저를 위협할 목적으로 따라다니거나 제가 소속되어 있는 클럽 밴드마다 꽃뱀 운운하는 댓글을 게시하고 있습니다. 또한 여러 정치계 인사(17년 모시장과 친구, 18년 모시장후보의 선거본부장, 현재는 더불어 민주당 부위원장)의 친분을 과시하고 돈을 뿌리며 구장마다 돌아다니면서 허위사실 유포 및 동호인들과 증인을 매수(친구처럼 지낸 동호인이 거짓 참고인 진술 등)하여 범죄를 방조하게 만들었습니다..저는 생각만 해도 치가 떨리는 지난 악몽과 피의자의 목소리를 수차례 쉼 없이 눈물을 흘리며 듣고 또 들으며, 피의자의 범죄를 인정받기 위해 수백만원을 들여 녹취록을 증거로 제출했으나 증거로 인정받지 못했습니다..저는 꽃뱀, 성매매범, 폭행범이 아닙니다..제발 제가 제출한 녹취록을 비롯한 모든 자료를 증거로 인정해 주시기 바랍니다..상습범죄자가 더는 사회질서를 어지럽히지 못하도록 구속하여 최고의 형벌로 다스려 주시기  바랍니다. [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7F1qorGqym7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = train['category']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro8D0rttvgl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b497b804-e93d-476d-ec68-7ebb9e367505"
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지 마시고.보편적으로 모든국민이 수긍할  수 있는 복지정책 펴 주시길 바랍니다..저도 신혼부부이지만 당첨되는 사람 로또되는 이런주택정책 반대합니다..국민세금을 일부 사람들에게 퍼주기식이 되면 안되죠...그 세금으로 우리아이 안전하게 맡길 수 있는 보육시설을 전국에 설치해 주세요...대기업들은 솔선수범해서 모든 사업장에 의무설치 할 수 있도록 하시구요...집 보다 애 맡길데가 없어 경력단절 되는게 더 괴롭습니다.!.집은 개인의 능력을 키워 사는게 맞습니다..그 능력을 키울수 있도록 육아 전담에 힘을 기울이는게 맞습니다..우리아이 부모가 키우는거 맞지만 이제는 국가가.책임지는 시대로 가는게 맞다고 봅니다..그렇잖아도 부동산 가격 자꾸 올라가는게 정부정책이 잘못 되었다고 봅니다..부동산은 그냥 내버려 두세요!  좀!.건들수록 역효과네요.. [SEP]\n",
            "['[CLS]', '신', '##혼', '##부', '##부', '##위', '##한', '주', '##택', '##정', '##책', '보다', '보', '##육', '##시', '##설', '늘', '##려', '##주', '##세', '##요', '.', '.', '국', '##민', '##세', '##금', '##으로', '일부', '##를', '위한', '정', '##책', '##펴', '##지', '마', '##시', '##고', '.', '보', '##편', '##적으로', '모든', '##국', '##민', '##이', '수', '##긍', '##할', '수', '있는', '복', '##지', '##정', '##책', '펴', '주', '##시', '##길', '바', '##랍', '##니다', '.', '.', '저', '##도', '신', '##혼', '##부', '##부', '##이지', '##만', '당', '##첨', '##되는', '사', '##람', '로', '##또', '##되는', '이런', '##주', '##택', '##정', '##책', '반', '##대', '##합', '##니다', '.', '.', '국', '##민', '##세', '##금', '##을', '일부', '사', '##람', '##들에게', '퍼', '##주', '##기', '##식', '##이', '되', '##면', '안', '##되', '##죠', '.', '.', '.', '그', '세', '##금', '##으로', '우', '##리아', '##이', '안', '##전', '##하게', '맡', '##길', '수', '있는', '보', '##육', '##시', '##설', '##을', '전', '##국', '##에', '설치', '##해', '주', '##세', '##요', '.', '.', '.', '대', '##기', '##업', '##들은', '솔', '##선', '##수', '##범', '##해서', '모든', '사', '##업', '##장에', '의', '##무', '##설', '##치', '할', '수', '있도록', '하', '##시', '##구', '##요', '.', '.', '.', '집', '보다', '애', '맡', '##길', '##데', '##가', '없', '##어', '경', '##력', '##단', '##절', '되는', '##게', '더', '괴', '##롭', '##습', '##니다', '.', '!', '.', '집', '##은', '개', '##인의', '능', '##력을', '키', '##워', '사', '##는', '##게', '맞', '##습', '##니다', '.', '.', '그', '능', '##력을', '키', '##울', '##수', '있도록', '육', '##아', '전', '##담', '##에', '힘', '##을', '기', '##울', '##이는', '##게', '맞', '##습', '##니다', '.', '.', '우', '##리아', '##이', '부', '##모', '##가', '키', '##우', '##는', '##거', '맞', '##지만', '이', '##제는', '국가', '##가', '.', '책', '##임', '##지는', '시대', '##로', '가', '##는', '##게', '맞', '##다고', '[UNK]', '.', '.', '[UNK]', '부', '##동', '##산', '가', '##격', '자', '##꾸', '올', '##라', '##가는', '##게', '정', '##부', '##정', '##책', '##이', '잘', '##못', '되었다', '##고', '[UNK]', '.', '.', '부', '##동', '##산', '##은', '그', '##냥', '내', '##버', '##려', '두', '##세', '##요', '!', '좀', '!', '.', '건', '##들', '##수', '##록', '역', '##효', '##과', '##네', '##요', '.', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd8r0dBfP-U1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "48c623e3-5c12-4aa8-dfef-83e3d2902d9a"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9487, 119439,  14646,  14646,  19855,  11102,   9689,\n",
              "       119342,  16605, 119254, 106154,   9356,  83811,  14040,  31928,\n",
              "         9044,  26737,  16323,  24982,  48549,    119,    119,   8909,\n",
              "        36553,  24982,  40032,  11467,  47807,  11513,  28195,   9670,\n",
              "       119254, 119396,  12508,   9246,  14040,  11664,    119,   9356,\n",
              "        50450,  17022,  25701,  20479,  36553,  10739,   9460, 118665,\n",
              "        14843,   9460,  13767,   9357,  12508,  16605, 119254,   9923,\n",
              "         9689,  14040, 118666,   9318, 118853,  48345,    119,    119,\n",
              "         9663,  12092,   9487, 119439,  14646,  14646,  44359,  19105,\n",
              "         9067, 119260,  24683,   9405,  61250,   9202, 118839,  24683,\n",
              "        80956,  16323, 119342,  16605, 119254,   9321,  14423,  33188,\n",
              "        48345,    119,    119,   8909,  36553,  24982,  40032,  10622,\n",
              "        47807,   9405,  61250,  61688,   9913,  16323,  12310,  21155,\n",
              "        10739,   9098,  14867,   9521, 118800, 119217,    119,    119,\n",
              "          119,   8924,   9435,  40032,  11467,   9604,  31065,  10739,\n",
              "         9521,  16617,  17594,   9257, 118666,   9460,  13767,   9356])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGqiGoEqv-hD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "042608da-10fb-4bf9-b03d-121a4d30916b"
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETWylaNryCUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "6f04a8bf-deaf-480b-a227-546223e3dbd4"
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels, \n",
        "                                                                                    random_state=7, \n",
        "                                                                                    test_size=0.2)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=7, \n",
        "                                                       test_size=0.2)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels.values)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels.values)\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,    112,   9344,  10739,  29455,   9319,  12605,    112,   9625,\n",
            "         12310,   9519,  18778,    117,   9670,  43875,   8900,  71013,  10739,\n",
            "          9949,  48549,  33188,  48345,    119,   9365, 118813,  10739,  11102,\n",
            "          9405,  16605,  11467,   9640,  13374,   9519,  29669,  67288,   9543,\n",
            "         83811,   9955,  15891,   9555,  14153,   9099,   9365,  39420,  11287,\n",
            "          9519,  66623,  84295,   8847,  15891, 107931,   9246, 101440,  13441,\n",
            "          9344,  10739,  29455,   9319,  12605,  10530,   9625,  12310,  13441,\n",
            "          9519,  12310, 107153,  10892,  10218, 106249,  10739,   9100, 118832,\n",
            "         18382,   9565,  12310,  48387,  12310,   9485,  31928,  10530,   9276,\n",
            "        118794,  11903,  50342,   9979, 119433,  24989,  25387,  11467,   9405,\n",
            "         14863,  10530,   8996, 118937,  62211,   9647, 119081,  48345,    119,\n",
            "           119,   9694, 119119,  16605,  14646,  12638, 105383,  13764,  18622,\n",
            "         24989,  29683,  11018,   9625,  12310,   9519,  69448,   9692,  10739,\n",
            "         12310,  19905,   9022,  28143,  10892,   9952,  46216,   9798, 118741,\n",
            "          9519,  18778])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n",
            "tensor([  101,  9768, 22333, 58931, 14423, 30134, 14423, 33188, 48345,   106,\n",
            "          106,   119,   100,   106,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCsPw_Wtx64t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 16\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdIzKVfi1Yca",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "#**Test set pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q49M7fW-1aFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "92b7fd34-69c7-437a-ae6f-752c2e1393b8"
      },
      "source": [
        "# 청원 문장 추출\n",
        "sentences = test['data']\n",
        "sentences[:10]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    소년법 폐지해주세요. 법 아래에서 보호받아야 할 아이들이\\n법으로 인해 보호받지 못...\n",
              "1    국공립 유치원 증설에 관하여. 국공립 유치원 부지 학보와건립및 증설에\\n*지역 어린...\n",
              "2                     나경원파면. 나경원의원의  동계올림픽 위원을 파면해 주세요\n",
              "3    국민위원에가 삼성편만들어요. 삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 ...\n",
              "4    방과후,유치원,어린이집 영어교육을 유지시켜주세요. 저는 아이 셋 키우는 평범한 주부...\n",
              "5    유은혜는 당장 사퇴하라!!!. 능력도 전문성도 없는 사람이 국회의윈 그리고 대통령의...\n",
              "6    신태용 감독. 노벨상 수상 청원합니다 !!!. 한국축구가 가장어려운 시기에,  용기...\n",
              "7    사회복무요원 최저임금 보장. 사회복무요원들은 의식주 보장이 아무것도 되질 않는데 왜...\n",
              "8    로또복권  의구심. 로또복귄 운영에  대한 민초들의  의구심을 해소하기 위하여 추첨...\n",
              "9    다자녀의기준이 뭘까요?. 오늘 상수도사업본부 감면신청을 보고 , 당황스러웠습니다. ...\n",
              "Name: data, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYjGFaIV1Z7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "9b1ba2af-01e9-4972-cabc-8a527a8d5a3a"
      },
      "source": [
        "# 스페셜 토큰 추가\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 소년법 폐지해주세요. 법 아래에서 보호받아야 할 아이들이\\\\n법으로 인해 보호받지 못하고 있습니다\\\\n오히려 법을 악용하는 사례만 늘어나고\\\\n그 강도는 높아지고 있습니다\\\\n소년법폐지를 부탁드립니다 [SEP]',\n",
              " '[CLS] 국공립 유치원 증설에 관하여. 국공립 유치원 부지 학보와건립및 증설에\\\\n*지역 어린이 놀이터 부지와 지역의 방대한 주민센터휴계부지 및 구청.시청.군청 청사공간부지 활용과 청년실업과 퇴직희망자가 재교육을 통해  유아.유치 업무에 종사하는 방법은 불가능한 건가요 [SEP]',\n",
              " '[CLS] 나경원파면. 나경원의원의  동계올림픽 위원을 파면해 주세요 [SEP]',\n",
              " '[CLS] 국민위원에가 삼성편만들어요. 삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 사람이 많아요~!!그래서 산업 제외을 받기 위해서 환경 평가표을 받아야 합니다 ~!!그래야 신청 할 수 있습니다 ~!법원에서도 평가표을 공개하라고 판결이 나지만 ..국가 국민위원에가 공개을 하지 못하겠 하고 있어요~!삼성이 환경평간표가 산업 기밀 이라고 다시 막았어요~!단 하루만에 피해자들은 11년동안 고통을 받고 있는데 ......!!!\\\\n제발  국민위원에가  국민을 위해  일해주세요\\\\n그리고 국민위원에서 독단으로. 처리한 분도 다시 감독 해주세요 [SEP]',\n",
              " '[CLS] 방과후,유치원,어린이집 영어교육을 유지시켜주세요. 저는 아이 셋 키우는 평범한 주부입니다\\\\n학교 방과후나 어린이집에서 받는 영어교육은\\\\n과하지않은 도움되는 교육이라 좋은점을 많이 느끼고\\\\n있는데 이렇게 없앤다고 하니 막막한 생각이 듭니다\\\\n학원을 보내기쉽지않은 경제상태인데 많은 시간을 배정받은 것도 아닌데.. 저처럼 도움받는 분들이\\\\n더욱 많은것으로 알고있는데 상황도 모르고 높은분들은 그저 토론 후 없애버리고있습니다..\\\\n영어를 쉽게 놀이처럼 받아들이며 배우는 작은 지역에서의\\\\n영어교육은 서울 수도권처럼 과하지않습니다..\\\\n영어유치원 원어민 선생님과 공부하는것도 아니고 소규모지역 부모들은 이 작은 교육도 지금 받지 못하게 됐어요 서울 수도권 영어교육은 규제해야될 정도로 과열되었을지 모르나 지역은 그렇지않습니다\\\\n수업일수도 여기는 부족하다싶은데 어디를 기준으로\\\\n이것이 시행되는지 모르겠습니다\\\\n무조건 없애고 줄인다는건 답이 없습니다\\\\n부디 한번더 두번더 생각하셔서 영어교육이 유지될수있도록 해주십시오 [SEP]',\n",
              " '[CLS] 유은혜는 당장 사퇴하라!!!. 능력도 전문성도 없는 사람이 국회의윈 그리고 대통령의 친분으로 인해 사회ㆍ교육부총리라는 중요한 자리에 낙하산으로 내정된 것은 적폐가 아나고 무엇이냐!\\\\n부총리 자리의 경중도 모르고, 총선 출마에 대한 확고한 인식도 없는 인간이 무슨 부총리냐?\\\\n정부와 내각은 총 사퇴하라!\\\\n정부는 제발 정신 좀 차리고, 나라 살림, 경제에 제발  신경 좀 써라!\\\\n남북관계는  이 정부 아니어도 언젠가는 좋아지고,\\\\n통일은 아직도 먼 얘기이며, 칼자루는 우리가 아닌 미국이 갖고 있지 않는가!\\\\n정신들 좀 차리고  살라!\\\\n국민들이 얼마나 힘든지 너희들은 아는가? 각성하라!!! [SEP]',\n",
              " '[CLS] 신태용 감독. 노벨상 수상 청원합니다 !!!. 한국축구가 가장어려운 시기에,  용기있기 감독을 맡아서 16강 진출보다 더 값진 독일전 승리의 신화를 이룬 신태용 국가대표 감독에게 감사의 표시로 노벨상 수상을 청원합니다. [SEP]',\n",
              " '[CLS] 사회복무요원 최저임금 보장. 사회복무요원들은 의식주 보장이 아무것도 되질 않는데 왜 최저임금을 보장해주지 않는거죠? 일 쉽게 한다고 배부른소리라고 할게 아니라 지킬건 지켜야 한다고 생각합니다 [SEP]',\n",
              " '[CLS] 로또복권  의구심. 로또복귄 운영에  대한 민초들의  의구심을 해소하기 위하여 추첨은 생방송으로  진행하는것이  지극히 타당하다고 봅니다. 하루속히  녹화방송을  생방송으로 바꿔주실것을  청윈 합니다. [SEP]',\n",
              " '[CLS] 다자녀의기준이 뭘까요?. 오늘 상수도사업본부 감면신청을 보고 , 당황스러웠습니다. 18세이하의 자녀3명이상이 신청대상이라네요.   저희는  23살 2명, 21세 1명, 20세 1명 즉 4명의 자녀를 둔 학부모입니다.  지금 이 시대를 살아가는 대가족의 한가정의로 안타까운 심정입니다. 지방자치단체에서 다자녀혜택은 물론이고 , 올해로 대학생자녀가 3명이 되지만, 한국장학재단의 다자녀혜택을 보지못하고 있습니다. 무엇이든지 행정이 정한 규칙이겠지만,  지금 이 어려운 시대를 살아가는 부모로써 슬픈현실입니다... [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGpXaI_81Zw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "cd31cbf8-ed8c-4435-e019-abccec3e7d6a"
      },
      "source": [
        "# 문장 단위\"\\\\n\" 제거\n",
        "sentences = [sentence.replace('\\\\n', '.') for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 소년법 폐지해주세요. 법 아래에서 보호받아야 할 아이들이.법으로 인해 보호받지 못하고 있습니다.오히려 법을 악용하는 사례만 늘어나고.그 강도는 높아지고 있습니다.소년법폐지를 부탁드립니다 [SEP]',\n",
              " '[CLS] 국공립 유치원 증설에 관하여. 국공립 유치원 부지 학보와건립및 증설에.*지역 어린이 놀이터 부지와 지역의 방대한 주민센터휴계부지 및 구청.시청.군청 청사공간부지 활용과 청년실업과 퇴직희망자가 재교육을 통해  유아.유치 업무에 종사하는 방법은 불가능한 건가요 [SEP]',\n",
              " '[CLS] 나경원파면. 나경원의원의  동계올림픽 위원을 파면해 주세요 [SEP]',\n",
              " '[CLS] 국민위원에가 삼성편만들어요. 삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 사람이 많아요~!!그래서 산업 제외을 받기 위해서 환경 평가표을 받아야 합니다 ~!!그래야 신청 할 수 있습니다 ~!법원에서도 평가표을 공개하라고 판결이 나지만 ..국가 국민위원에가 공개을 하지 못하겠 하고 있어요~!삼성이 환경평간표가 산업 기밀 이라고 다시 막았어요~!단 하루만에 피해자들은 11년동안 고통을 받고 있는데 ......!!!.제발  국민위원에가  국민을 위해  일해주세요.그리고 국민위원에서 독단으로. 처리한 분도 다시 감독 해주세요 [SEP]',\n",
              " '[CLS] 방과후,유치원,어린이집 영어교육을 유지시켜주세요. 저는 아이 셋 키우는 평범한 주부입니다.학교 방과후나 어린이집에서 받는 영어교육은.과하지않은 도움되는 교육이라 좋은점을 많이 느끼고.있는데 이렇게 없앤다고 하니 막막한 생각이 듭니다.학원을 보내기쉽지않은 경제상태인데 많은 시간을 배정받은 것도 아닌데.. 저처럼 도움받는 분들이.더욱 많은것으로 알고있는데 상황도 모르고 높은분들은 그저 토론 후 없애버리고있습니다...영어를 쉽게 놀이처럼 받아들이며 배우는 작은 지역에서의.영어교육은 서울 수도권처럼 과하지않습니다...영어유치원 원어민 선생님과 공부하는것도 아니고 소규모지역 부모들은 이 작은 교육도 지금 받지 못하게 됐어요 서울 수도권 영어교육은 규제해야될 정도로 과열되었을지 모르나 지역은 그렇지않습니다.수업일수도 여기는 부족하다싶은데 어디를 기준으로.이것이 시행되는지 모르겠습니다.무조건 없애고 줄인다는건 답이 없습니다.부디 한번더 두번더 생각하셔서 영어교육이 유지될수있도록 해주십시오 [SEP]',\n",
              " '[CLS] 유은혜는 당장 사퇴하라!!!. 능력도 전문성도 없는 사람이 국회의윈 그리고 대통령의 친분으로 인해 사회ㆍ교육부총리라는 중요한 자리에 낙하산으로 내정된 것은 적폐가 아나고 무엇이냐!.부총리 자리의 경중도 모르고, 총선 출마에 대한 확고한 인식도 없는 인간이 무슨 부총리냐?.정부와 내각은 총 사퇴하라!.정부는 제발 정신 좀 차리고, 나라 살림, 경제에 제발  신경 좀 써라!.남북관계는  이 정부 아니어도 언젠가는 좋아지고,.통일은 아직도 먼 얘기이며, 칼자루는 우리가 아닌 미국이 갖고 있지 않는가!.정신들 좀 차리고  살라!.국민들이 얼마나 힘든지 너희들은 아는가? 각성하라!!! [SEP]',\n",
              " '[CLS] 신태용 감독. 노벨상 수상 청원합니다 !!!. 한국축구가 가장어려운 시기에,  용기있기 감독을 맡아서 16강 진출보다 더 값진 독일전 승리의 신화를 이룬 신태용 국가대표 감독에게 감사의 표시로 노벨상 수상을 청원합니다. [SEP]',\n",
              " '[CLS] 사회복무요원 최저임금 보장. 사회복무요원들은 의식주 보장이 아무것도 되질 않는데 왜 최저임금을 보장해주지 않는거죠? 일 쉽게 한다고 배부른소리라고 할게 아니라 지킬건 지켜야 한다고 생각합니다 [SEP]',\n",
              " '[CLS] 로또복권  의구심. 로또복귄 운영에  대한 민초들의  의구심을 해소하기 위하여 추첨은 생방송으로  진행하는것이  지극히 타당하다고 봅니다. 하루속히  녹화방송을  생방송으로 바꿔주실것을  청윈 합니다. [SEP]',\n",
              " '[CLS] 다자녀의기준이 뭘까요?. 오늘 상수도사업본부 감면신청을 보고 , 당황스러웠습니다. 18세이하의 자녀3명이상이 신청대상이라네요.   저희는  23살 2명, 21세 1명, 20세 1명 즉 4명의 자녀를 둔 학부모입니다.  지금 이 시대를 살아가는 대가족의 한가정의로 안타까운 심정입니다. 지방자치단체에서 다자녀혜택은 물론이고 , 올해로 대학생자녀가 3명이 되지만, 한국장학재단의 다자녀혜택을 보지못하고 있습니다. 무엇이든지 행정이 정한 규칙이겠지만,  지금 이 어려운 시대를 살아가는 부모로써 슬픈현실입니다... [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTNZEiLw1Zjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [0] *1000"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOxM-Z9Q1ZBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "632b5bfc-605a-43ec-f797-347efe78bcfc"
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 소년법 폐지해주세요. 법 아래에서 보호받아야 할 아이들이.법으로 인해 보호받지 못하고 있습니다.오히려 법을 악용하는 사례만 늘어나고.그 강도는 높아지고 있습니다.소년법폐지를 부탁드립니다 [SEP]\n",
            "['[CLS]', '소', '##년', '##법', '폐', '##지', '##해', '##주', '##세', '##요', '.', '법', '아', '##래', '##에서', '보', '##호', '##받', '##아', '##야', '할', '아', '##이', '##들이', '.', '법', '##으로', '인해', '보', '##호', '##받', '##지', '못', '##하고', '있', '##습', '##니다', '.', '오', '##히', '##려', '법', '##을', '악', '##용', '##하는', '사', '##례', '##만', '늘', '##어', '##나', '##고', '.', '그', '강', '##도는', '높', '##아', '##지고', '있', '##습', '##니다', '.', '소', '##년', '##법', '##폐', '##지를', '부', '##탁', '##드', '##립', '##니다', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZZKwERG1YL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e8a0c884-42a4-4436-fe12-4d0a48b238ae"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9448,  10954,  33768,   9927,  12508,  14523,  16323,\n",
              "        24982,  48549,    119,   9341,   9519,  37388,  11489,   9356,\n",
              "        20309, 118965,  16985,  21711,   9955,   9519,  10739,  20173,\n",
              "          119,   9341,  11467,  39629,   9356,  20309, 118965,  12508,\n",
              "         9290,  12453,   9647, 119081,  48345,    119,   9580,  18108,\n",
              "        26737,   9341,  10622,   9520,  24974,  12178,   9405,  58762,\n",
              "        19105,   9044,  12965,  16439,  11664,    119,   8924,   8853,\n",
              "        60884,   9028,  16985,  68833,   9647, 119081,  48345,    119,\n",
              "         9448,  10954,  33768, 119399,  36908,   9365, 119335,  15001,\n",
              "        35115,  48345,    102,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7eQZtOy1vug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7feaa252-a297-4f8b-8e65-73c6db140932"
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3KOB6fg1vnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "da367f9a-38e9-407d-da96-52c0c56f8fe5"
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,   9448,  10954,  33768,   9927,  12508,  14523,  16323,  24982,\n",
            "         48549,    119,   9341,   9519,  37388,  11489,   9356,  20309, 118965,\n",
            "         16985,  21711,   9955,   9519,  10739,  20173,    119,   9341,  11467,\n",
            "         39629,   9356,  20309, 118965,  12508,   9290,  12453,   9647, 119081,\n",
            "         48345,    119,   9580,  18108,  26737,   9341,  10622,   9520,  24974,\n",
            "         12178,   9405,  58762,  19105,   9044,  12965,  16439,  11664,    119,\n",
            "          8924,   8853,  60884,   9028,  16985,  68833,   9647, 119081,  48345,\n",
            "           119,   9448,  10954,  33768, 119399,  36908,   9365, 119335,  15001,\n",
            "         35115,  48345,    102,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YCZrSmRxNBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배치 사이즈\n",
        "#batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "#test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "#test_sampler = RandomSampler(test_data)\n",
        "#test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fYUM13r2ZCf",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "#**Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqNWVq21xR6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9946ffc3-b0f2-4502-be27-3ea7914e6574"
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=3)\n",
        "model.cuda()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iduI9s_zxdhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 4\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3ggL2_O3A31",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Model Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW4ewmEGxvND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvDYGlRw3Io4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUp1g0Y23IiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "a53fdbc9-abd3-4f94-ffa3-90d3545412f1"
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.cuda() for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  2,000.    Elapsed: 0:05:53.\n",
            "  Batch 1,000  of  2,000.    Elapsed: 0:11:45.\n",
            "  Batch 1,500  of  2,000.    Elapsed: 0:17:38.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:23:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:01:46\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  2,000.    Elapsed: 0:05:52.\n",
            "  Batch 1,000  of  2,000.    Elapsed: 0:11:44.\n",
            "  Batch 1,500  of  2,000.    Elapsed: 0:17:36.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:23:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:01:46\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  2,000.    Elapsed: 0:05:52.\n",
            "  Batch 1,000  of  2,000.    Elapsed: 0:11:44.\n",
            "  Batch 1,500  of  2,000.    Elapsed: 0:17:36.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:23:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:01:46\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  2,000.    Elapsed: 0:05:52.\n",
            "  Batch 1,000  of  2,000.    Elapsed: 0:11:43.\n",
            "  Batch 1,500  of  2,000.    Elapsed: 0:17:35.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:23:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:01:46\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmtYsu5U3QeM",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **테스트셋 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP80FJx73IUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    \n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prrjvbP63IOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 넣음\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "            \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbAQhKbY3IHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "50946e61-2d5c-4489-8176-eea96f654cd1"
      },
      "source": [
        "logits = test_sentences(['연기는 별로지만 재미 하나는 끝내줌!'])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.68872225  2.1478376  -1.2678936 ]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "631UC2mzKnvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}